{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r2-8RWgeqfBy"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "import io\n",
        "import sys\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet34\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import os \n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import pathlib\n",
        "from   torch.utils.data import  DataLoader\n",
        "from   skimage import color\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "      def __init__(self, num_classes=11):\n",
        "          super(Net, self).__init__()\n",
        "          self.features   = nn.Sequential(\n",
        "                                nn.Conv2d(1, 32, kernel_size=3, stride=1, padding='same'), \n",
        "                                nn.BatchNorm2d(32),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.MaxPool2d(kernel_size=2, stride=1), \n",
        "                                nn.Conv2d(32, 64, kernel_size=3, padding='same'),\n",
        "                                nn.BatchNorm2d(64),\n",
        "                                nn.ReLU(inplace=True), \n",
        "                                nn.Conv2d(64, 128, kernel_size=3, padding='same'), \n",
        "                                nn.BatchNorm2d(128),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(128, 128, kernel_size=3, padding='same'), \n",
        "                                nn.BatchNorm2d(128),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.MaxPool2d(kernel_size=2, stride=1),)\n",
        "          \n",
        "          self.avgpool    = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "          self.classifier = nn.Sequential(\n",
        "                                nn.Dropout(0.2), \n",
        "                                nn.Linear(128 * 7 * 7, 4096), \n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Linear(4096, 4096), \n",
        "                                nn.ReLU(inplace=True), \n",
        "                                nn.Linear(4096, num_classes),)\n",
        "          \n",
        "      def forward(self, x):\n",
        "          x = self.features(x)\n",
        "          x = self.avgpool(x)\n",
        "          x = x.view(-1, 128*7*7)\n",
        "          x = self.classifier(x)\n",
        "          return x"
      ],
      "metadata": {
        "id": "P7VSsqmdk09o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier:\n",
        "    def __init__(self):\n",
        "        # Class module from AI team        \n",
        "        self.classifier = Net()\n",
        "        # Model path with pth file\n",
        "        model_path = 'drive/MyDrive/model/ModelAug.pth'               \n",
        "        self.classifier.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "\n",
        "    def preprocessing(self, image):\n",
        "      transform =transforms.Compose([transforms.Resize((128,128)),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(), \n",
        "                                     transforms.Normalize([0.5,], [0.5,]),\n",
        "                                     transforms.Grayscale(1)\n",
        "                                    ])\n",
        "      image = transform(image).float()\n",
        "      return image\n",
        "\n",
        "    def predict(self, image):\n",
        "        # Preprocessing image\n",
        "        image = cv2.imread(image, 3)\n",
        "        image = Image.fromarray(image)\n",
        "        image_tensor = self.preprocessing(image).float()\n",
        "        image_tensor = image_tensor.unsqueeze_(0)\n",
        "        image = Variable(image_tensor)    \n",
        "        # Predict image from classifier\n",
        "        output = self.classifier(image)\n",
        "        index = output.data.numpy().argmax()\n",
        "        with open('class.txt', 'r') as f:\n",
        "          to_label = eval(f.read())\n",
        "        # Get result final and return it\n",
        "        result_final = to_label[index]\n",
        "        return result_final"
      ],
      "metadata": {
        "id": "UC6_m4EjA7jZ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREDICTION"
      ],
      "metadata": {
        "id": "dv7eY6RkizDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call Image Classifier class for BE side\n",
        "image_classifier = ImageClassifier()"
      ],
      "metadata": {
        "id": "dXFiu65uqgsk"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jury Test Set"
      ],
      "metadata": {
        "id": "Tqx22kwz9koI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing image\n",
        "image = 'hat_3.jpg'\n",
        "predicted_class = image_classifier.predict(image)\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "id": "o1I3TpMeqjZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71f5b18-1091-41c8-8d64-e74d89df5595"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'hat_4.jpg'\n",
        "predicted_class = image_classifier.predict(image)\n",
        "\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uajG5hJ_Hqzx",
        "outputId": "c8fafca9-8f68-4ee7-f936-96d1a74662c0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'trouser_1.jpg'\n",
        "predicted_class = image_classifier.predict(image)\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlA4lOYh9nkN",
        "outputId": "5e5fff93-f9d1-4192-ca20-963c4dae06c6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dress\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = '116537_BLAC_1.jpg'\n",
        "predicted_class = image_classifier.predict(image)\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7U6ucVwK0qK",
        "outputId": "381d9bcb-73a0-481b-8014-7be666dccb9e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trouser\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'sandal_1.jpeg'\n",
        "predicted_class = image_classifier.predict(image)\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfQLSNSY-Uh8",
        "outputId": "015f644e-0474-4804-ce25-1f9cf2b0aaf0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sandal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'mnist_58.png'\n",
        "predicted_class = image_classifier.predict(image)\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE2H6Xui-aq7",
        "outputId": "934ca0fe-dea8-480d-83db-daa1f3c000eb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dress\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'mnist_41.png'\n",
        "predicted_class = image_classifier.predict(image)\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcxCUvDXHM0p",
        "outputId": "9cf2baed-803d-4377-d5dd-ed3d4dab707f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sneaker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'mnist_35_bag.png'\n",
        "predicted_class = image_classifier.predict(image)\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FziwPb-BHgV4",
        "outputId": "5efef90a-d74b-4c0e-a6a4-dc813ab46626"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'mnist_112.png'\n",
        "predicted_class = image_classifier.predict(image)\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KIoofkXHknJ",
        "outputId": "ce38c306-e30e-44b0-edc1-c9dc799a5f78"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shirt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'mnist_11_shoes.png'\n",
        "predicted_clas = image_classifier.predict(image)\n",
        "print(predicted_clas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-C5GzqCH0ug",
        "outputId": "63958428-fc29-4197-da8a-fd8678f52ddd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shirt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'tes_ankle.jpg'\n",
        "predicted_clas = image_classifier.predict(image)\n",
        "print(predicted_clas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jetwMj3MFo8",
        "outputId": "9e5f24da-69fb-42db-f7c4-2697582ff201"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankle Boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'tes_ankle_1.jpg'\n",
        "predicted_clas = image_classifier.predict(image)\n",
        "print(predicted_clas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiNhLiQlMSZe",
        "outputId": "601e0ebf-219a-45ae-805f-b420521b7f01"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankle Boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = '372.jpg'\n",
        "predicted_clas = image_classifier.predict(image)\n",
        "print(predicted_clas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzJhN5uDLIVN",
        "outputId": "4c3c31f1-be26-4546-91fe-6c961f87349f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankle Boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = '1332.jpg'\n",
        "predicted_clas = image_classifier.predict(image)\n",
        "print(predicted_clas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FfR1GneLSQn",
        "outputId": "4f3eaecd-c257-4bcf-cc2f-5f1d8877cffd"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankle Boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'mnist_358.png'\n",
        "predicted_clas = image_classifier.predict(image)\n",
        "print(predicted_clas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYOgebNMIE85",
        "outputId": "1bd6d0a4-58c3-4048-bae5-b9f42d9455ad"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag\n"
          ]
        }
      ]
    }
  ]
}